Q1:
1   1   1.0   1.5217889895115522   1   1.5217889895115522   7.5914975070521375
2   2   0.9   -0.584216103776544   1   -0.584216103776544   5.4854924137640415
3   3   0.8   0.270956751054684   1   0.270956751054684   6.34066526859527
4   4   0.7   -0.2685492072417319   1   -0.2685492072417319   5.8011593102988535
5   5   0.6   -0.3151703809718187   1   -0.3151703809718187   5.754538136568767
6   6   0.5   0.06181451778333885   1   0.06181451778333885   6.131523035323925
7   7   0.4   -0.7320271832944979   1   -0.7320271832944979   5.337681334246088
8   8   0.3   1.6295134406192102   1   1.6295134406192102   7.6992219581597965
9   9   0.2   -0.037318974474803784   1   -0.037318974474803784   6.032389543065782
10   10   0.1   -0.29386950331189676   1   -0.29386950331189676   5.775839014228689
11   11   0.0   -0.19663447893594127   1   -0.19663447893594127   5.873074038604645
12   8   0.3   -0.05776720293536958   2   0.7858731188419203   5.077805171420614
13   1   1.0   0.3644810698741505   2   0.9431350296928513   5.235067082271546
14   3   0.8   0.14131591471210259   2   0.20613633288339328   4.498068385462088
15   6   0.5   1.5462283860236716   2   0.8040214519035053   5.0959535044822
16   9   0.2   -0.2698397013631509   2   -0.15357933791897732   4.138352714659717
17   11   0.0   1.2620618720730707   2   0.5327136965685647   4.824645749147259
18   4   0.7   -0.07243206695014537   2   -0.17049063709593865   4.121441415482756
19   10   0.1   0.3697583795659932   2   0.03794443812704823   4.329876490705742
20   5   0.6   1.0102927766847911   2   0.3475611978564862   4.639493250435181

Q2:
a) T:  [7031, 1730, 511, 252, 160, 113, 66, 53, 23, 32, 29]
In the beginning of n trials, the probability of each arm being chosen is relatively equal. After updating UCB for trials, the distinction between upper bounds of arms becomes larger and thus the one with higher mu would be preffered more. In the end the confident interval would be small enough and the algorithm would pick the optimal almost everytime.
c) mu_hs:  [0.9979382384032764, 0.9204673575627803, 0.7982215224285897, 0.682290526382576, 0.5859788276353599, 0.4907065676160944, 0.30710334813101436, 0.2232047282243975, -0.2092831119783296, -0.036537681913946726, -0.06198624031024917]
The mu_hs of the arms w/ lower mu is not very accurate since the algorithm focus on the arms provides higher rewards or have higher mu (the mu_h of arms w/ lower mu would not get updated frequently after few trials), thus the accuracy of the first few arms are pretty high.
d) UCBs:  [1.0703250231513166, 1.0663974253181592, 1.0667296188124573, 1.0646462232412168, 1.065831418854168, 1.061696714361704, 1.0542328193650405, 1.0569433131979336, 1.0563386030538815, 1.036445331230727, 1.0651303354905821]
Still, the UCB of the first/optimal one is pretty accurate while not very accurate for later one. That's because once the UCB of other arms becomes smaller than mu_h of optimal arm + small value, they won't have much chance to update their UCB (t and mu_h) for a long period (even updated, will just keep their UCB smaller than the optimal arm's UCB)

Q3ï¼š
mean dr_R:  636.9162322475236
mean random_R:  629.2001238881963
mean pseudo_R:  619.2360000000215

Q4:
1   1   -0.25573712473889954   1   -0.25573712473889954
2   2   1.194715868404561   1   1.194715868404561
3   3   -0.20175254630855188   1   -0.20175254630855188
4   4   -0.09422702242360625   1   -0.09422702242360625
5   5   0.9718180848939024   1   0.9718180848939024
6   6   0.847196420113864   1   0.847196420113864
7   7   0.7216928136081702   1   0.7216928136081702
8   8   0.5228836885541108   1   0.5228836885541108
9   9   -1.4290898115051303   1   -1.4290898115051303
10   10   -0.6561712203437032   1   -0.6561712203437032
11   11   1.867238364489464   1   1.867238364489464
12   11   1.4506121869162114   2   1.6589252757028377
13   11   -0.037266697093908695   3   1.0935279514372556
14   2   1.1699780140581504   2   1.1823469412313556
15   2   0.7065780042675418   3   1.023757295576751
16   11   0.8473890023063825   4   1.0319932141545374
17   11   1.1290141664223388   5   1.0513974046080976
18   11   0.6744616095109718   6   0.9885747720919099
19   2   2.0205190195941896   4   1.2729477265811107
20   2   1.4670166037455568   5   1.3117615020139999

Q5:
mean of nn_R:  1332.7938836022245
standard devietion of nn_R:  1424.3072822253944
Why follow the leader is inferior? If initially the optimal arm got bad lucks for multiple times, it won't get chance to be selected unless the one with highest mu_h got some very low rewards. Thus it would be hard to distinguish the optimal one and the second optimal one

Q6:
Iteration 1 : -----------------------------------------------
X 1  =  0.06709013091422744
V 1  =  [[26.  5.]
 [ 5.  2.]]
hat_theta_ 1  =  [[0.0124241 ]
 [0.00248482]]
Iteration 2 : -----------------------------------------------
UCB 1, 2, 5, 999, 1000 = [[4.1956399]] [[3.70020659]] [[695.78643739]] [[1393.65645627]] [[1395.05499816]]
A 2  =  [[1000]
 [   1]]
X 2  =  0.09987192881740672
V 2  =  [[1.000026e+06 1.005000e+03]
 [1.005000e+03 3.000000e+00]]
hat_theta_ 2  =  [[6.67445884e-05]
 [3.32945828e-02]]
Iteration 3 : -----------------------------------------------
UCB 1, 2, 5, 999, 1000 = [[4.47816443]] [[4.47367288]] [[3.86915694]] [[6.31719841]] [[6.32353616]]
A 3  =  [[1000]
 [   1]]
X 3  =  -0.48379448575391887
V 3  =  [[2.000026e+06 2.005000e+03]
 [2.005000e+03 4.000000e+00]]
hat_theta_ 3  =  [[-0.0002259 ]
 [ 0.03402421]]
Iteration 4 : -----------------------------------------------
UCB 1, 2, 5, 999, 1000 = [[4.52400043]] [[4.5194674]] [[3.19416545]] [[4.51267636]] [[4.51720259]]
A 4  =  [[1]
 [1]]
X 4  =  0.4449685584168962
V 4  =  [[2.000027e+06 2.006000e+03]
 [2.006000e+03 5.000000e+00]]
hat_theta_ 4  =  [[-0.00036357]
 [ 0.17149295]]

Q7:
1 :  953
5 :  1
1000 :  46
total_reward: 1007.8181909051947
UCB_total_reward: 965.7598415802485